{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import stem  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def re_rule(x):\n",
    "    if re.search(\"[a-z0-9]+\",x) != None :\n",
    "        return re.search(\"[a-z0-9]+\",x).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.',',','\"',\"'\",'?','!',':',';','(',')','[rm]','[',']','{','}'])\n",
    "wordnet_lemm = stem.WordNetLemmatizer()\n",
    "\n",
    "def NLP_process(Sentence):\n",
    "    try:\n",
    "        words_result = []\n",
    "        words_now = word_tokenize(Sentence)\n",
    "        words_result = words_now\n",
    "        words_now = [i.lower() for i in words_result if i.lower() not in stop_words]\n",
    "        words_result = words_now\n",
    "        words_now =  [re_rule(w) for w in words_result]\n",
    "        words_result = []\n",
    "        for w in words_now:\n",
    "            if w != None :\n",
    "                words_result.append(\n",
    "                    wordnet_lemm.lemmatize(w))\n",
    "        return words_result\n",
    "    except:\n",
    "        print(Sentence)\n",
    "        return([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nwot', 'look', 'cool', 'trend', 'striped', 'midi', 'bodycon', 'dress', 's', 'easy', 'style', 'down', 'pair', 'black', 'heel', 'sandal', 'casual', 'look', 're', 'good', 'go', 'new', 'purchase', 'rm', 'excluding', 'shipping', 'get', 'sweet', 'surprise', 'gift', 'stretchy', 'lace', 'thong', 'style', 'panty', 'brand', 'new', 'tag']\n"
     ]
    }
   ],
   "source": [
    "Sentence = \"▪️nwot Look cool and on trend in this striped midi bodycon dress. It's easy to style up or down- pair with black heels (or sandals for a more casual look) and you're good to go! ❤️NEW! All purchases over [rm] (excluding shipping) will get a sweet surprise gift!❤️ Stretchy lace thong style panties brand new with tags.\"\n",
    "print(NLP_process(Sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(\"train.tsv\",delimiter = '\\t')\n",
    "Test = pd.read_csv(\"test.tsv\",delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_Meta = pd.concat([Train.train_id,Train.category_name,Train.item_description,Train.price],axis =1)\n",
    "Test_Meta = pd.concat([Test.test_id, Test.category_name ,Test.item_description],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_id      category_name    item_description  price\n",
      "0         0  Men/Tops/T-shirts  No description yet   10.0\n",
      "   test_id        category_name item_description\n",
      "0        0  Women/Jewelry/Rings           Size 7\n"
     ]
    }
   ],
   "source": [
    "print(Train_Meta.head(1))\n",
    "print(Test_Meta.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_Meta = Train_Meta.rename(columns={'train_id':'id'})\n",
    "Test_Meta = Test_Meta.rename(columns = {'test_id':'id'})\n",
    "Train_Meta['if_Train'] = 1\n",
    "Test_Meta['if_Train'] = 0\n",
    "Train_and_Test = pd.concat(\n",
    "    [Train_Meta.drop(['price'],axis=1),Test_Meta],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_and_Test.category_name = Train_and_Test.category_name.astype('category')\n",
    "Category_Dict = dict( enumerate(Train_and_Test['category_name'].cat.categories))\n",
    "Train_and_Test.category_name = Train_and_Test.category_name.cat.codes\n",
    "Coded_Train = Train_and_Test.loc[Train_and_Test['if_Train'] == 1]\n",
    "Coded_Test = Train_and_Test.loc[Train_and_Test['if_Train'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Coded_Train = Coded_Train.drop(['if_Train'],axis = 1)\n",
    "Coded_Test = Coded_Test.drop(['if_Train'],axis = 1)\n",
    "Coded_Train['price'] = Train_Meta.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Train\n",
    "del Test\n",
    "del Train_Meta\n",
    "del Test_Meta\n",
    "del Train_and_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n"
     ]
    }
   ],
   "source": [
    "#determine if train include all category data\n",
    "Cate_List = []\n",
    "for cate in Coded_Train.category_name :\n",
    "    if cate not in Cate_List:\n",
    "        Cate_List.append(cate)\n",
    "print(len(Cate_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "165\n",
      "171\n",
      "172\n",
      "182\n",
      "215\n",
      "219\n",
      "234\n",
      "239\n",
      "277\n",
      "286\n",
      "288\n",
      "353\n",
      "383\n",
      "386\n",
      "392\n",
      "411\n",
      "419\n",
      "692\n",
      "701\n",
      "795\n",
      "873\n",
      "975\n"
     ]
    }
   ],
   "source": [
    "No\n",
    "for i in range(len(Category_Dict)):\n",
    "    if i not in Cate_List:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "Coded_Train.item_description = Coded_Train.item_description.apply(NLP_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  category_name    item_description  price\n",
      "0   0            829  [description, yet]   10.0\n"
     ]
    }
   ],
   "source": [
    "print(Coded_Train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#根據category分開\n",
    "Cate_Dict = [ dict() for i in range(len(Category_Dict))]\n",
    "Split_By_Category = [None for i in range(len(Category_Dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(Category_Dict)):\n",
    "    Split_By_Category[i] = Coded_Train.loc[Coded_Train['category_name'] == i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateCateDict(DF,cate_dict_list,the_index,p_mean,p_std):\n",
    "    #print(DF['price'],DF['item_description'])\n",
    "    the_dict = cate_dict_list[the_index]\n",
    "    if p_std == 0:\n",
    "        x_std = 0\n",
    "    else:\n",
    "        x_std = (DF['price'] - p_mean) / p_std\n",
    "        if x_std == float('nan'):\n",
    "            print(DF['price'],DF['item_description'])\n",
    "            print(the_index,p_mean,p_std)\n",
    "    for word in DF['item_description']:        \n",
    "        if the_dict.get(word) == None:\n",
    "            the_dict[word] = [x_std]\n",
    "        else:\n",
    "            the_dict[word].append(x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for  i in range(len(Category_Dict)):\n",
    "    Cate_Data =  Split_By_Category[i]\n",
    "    if Split_By_Category[i].empty != True and len(Split_By_Category[i]) != 1:\n",
    "        price_mean = Cate_Data.price.mean()\n",
    "        price_std  = Cate_Data.price.std()\n",
    "        #print(Cate_Data.head(2))\n",
    "        Cate_Data.apply(updateCateDict,args=(\n",
    "            Cate_Dict,i,price_mean,price_std),axis = 1)\n",
    "    else:\n",
    "        ;#print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "            id  category_name  \\\n",
      "955791  955791            438   \n",
      "\n",
      "                                         item_description  price  \n",
      "955791  [100, organic, really, work, come, bamboo, bio...   20.0  \n"
     ]
    }
   ],
   "source": [
    "print(Cate_Dict[438])\n",
    "print((Split_By_Category[438]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  i in range(len(Category_Dict)):\n",
    "    if Cate_Dict[i] != dict():\n",
    "        for key in Cate_Dict[i]:\n",
    "            try:\n",
    "                value = (np.mean(Cate_Dict[i][key]))\n",
    "                Cate_Dict[i][key] = value\n",
    "            except:\n",
    "                print(key,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Descript_Meta.json\",'w') as o_f:\n",
    "    json.dump(Cate_Dict,o_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Descript_Meta.json\",'r') as i_f:\n",
    "    Value_Dict = json.loads(i_f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category_Dictionary = {}\n",
    "for key in Category_Dict:\n",
    "    Category_Dictionary[Category_Dict[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Category_Meta.json\",'w') as o_f:\n",
    "    json.dump(Category_Dictionary,o_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Category_Meta.json\",'r') as i_f:\n",
    "    C_Dict = json.loads(i_f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(C_Dict.get('Beauty/Bath & Body/Bath'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
